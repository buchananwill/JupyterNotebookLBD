{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:50.290757Z",
     "start_time": "2024-07-04T19:52:50.288007Z"
    }
   },
   "source": [
    "\n",
    "import string\n",
    "from functools import partial\n",
    "\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import plotly as pl\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# from scipy import stats\n",
    "from IPython.display import display\n",
    "# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ],
   "outputs": [],
   "execution_count": 277
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:50.425246Z",
     "start_time": "2024-07-04T19:52:50.422679Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "101b220ed97b51c1",
   "outputs": [],
   "execution_count": 277
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Predictive Measures\n",
    "1. Each match pulls in data from these most preceding data points:\n",
    "    1. Five fixtures of each team against any rival at home TEAM_any_rival_home_RECENCY.\n",
    "    2. Five fixtures of each team against any rival away TEAM_any_rival_away_RECENCY.\n",
    "    3. Five encounters of these two teams in matching home/away configuration matching_encounter_RECENCY.\n",
    "    4. Five encounters of these two teams in inverted home/away configuration inverted_encounter_RECENCY.   \n",
    "2. These metrics are collected and labelled separately for each of these 20 fixtures:\n",
    "    1. Goals for\n",
    "    2. Goals against\n",
    "    3. Points earned\n",
    "3. These aggregate columns are also added:\n",
    "    1. Goal difference (direct encounter)\n",
    "    2. Goal difference (any encounter)\n",
    "    3. Points difference (direct encounter)\n",
    "    4. Points difference (any encounter)\n",
    "\n",
    "Example row initial data:\n",
    "\n",
    "index | date | home_team | away_team | full_time_home_goals | full_time_away_goals | full_time_points_home | full_time_points_away |\n",
    "\n",
    "For each row, the previous 30 fixtures matching the given criteria will add this data:\n",
    "\n",
    "goals_for_CRITERION | goals_against_CRITERION | points_earned_CRITERION | days_since_CRITERION\n",
    "\n",
    "An example criterion would be: home_any_rival_home_1 - specifying the most recent match of the current home team, against any rival\n",
    "\n",
    "An example column would be: goals_for_home_any_rival_home_1\n",
    "An example column would be: days_since_any_rival_home_1"
   ],
   "id": "86eacfac997c41f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:50.461596Z",
     "start_time": "2024-07-04T19:52:50.457254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define criteria labels\n",
    "\n",
    "# team classifier\n",
    "home = \"home\"\n",
    "away = \"away\"\n",
    "\n",
    "# match type classifier \n",
    "any_rival_home = \"any_rival_home\"\n",
    "any_rival_away = \"any_rival_away\"\n",
    "matching_encounter = \"matching_encounter\"\n",
    "inverted_encounter = \"inverted_encounter\"\n",
    "\n",
    "# outcome classifiers\n",
    "goals_for = \"goals_for\"\n",
    "goals_against = \"goals_against\"\n",
    "points_earned = \"points_earned\"\n",
    "days_since = \"days_since\"\n",
    "\n",
    "outcome_criteria = [goals_for, goals_against, points_earned, days_since]\n",
    "team_criteria = [home, away]\n",
    "match_type_criteria = [matching_encounter, inverted_encounter, any_rival_home, any_rival_away]\n",
    "\n",
    "\n",
    "\n",
    "# Generate criteria combinations\n",
    "criteria_combinations = [\n",
    "    [outcome, team, match_type]\n",
    "    for outcome in outcome_criteria\n",
    "    for team in team_criteria\n",
    "    for match_type in match_type_criteria\n",
    "]\n",
    "\n",
    "# Generate all criteria combinations with recency\n",
    "all_criteria_combinations = [\n",
    "    combination + [recency]\n",
    "    for recency in range(1, 6)\n",
    "    for combination in criteria_combinations\n",
    "]\n",
    "\n",
    "print(len(all_criteria_combinations))"
   ],
   "id": "52a03f12980d2e03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "execution_count": 278
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:50.557428Z",
     "start_time": "2024-07-04T19:52:50.553618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to calculate points\n",
    "def calculate_points(row):\n",
    "    if row['full_time_home_goals'] > row['full_time_away_goals']:\n",
    "        home_points = 3\n",
    "        away_points = 0\n",
    "    elif row['full_time_home_goals'] == row['full_time_away_goals']:\n",
    "        home_points = 1\n",
    "        away_points = 1\n",
    "    else:\n",
    "        home_points = 0\n",
    "        away_points = 3\n",
    "    return pd.Series([home_points, away_points])"
   ],
   "id": "8472df0b9cdca80a",
   "outputs": [],
   "execution_count": 279
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:50.584720Z",
     "start_time": "2024-07-04T19:52:50.578434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to extract data points for each record\n",
    "def extract_data_points(record, df_param, combinations):\n",
    "    data_points = {}\n",
    "    for combo in combinations:\n",
    "        outcome, team, match_type, recency = combo\n",
    "        date = record['date']\n",
    "        team_name = record[team]\n",
    "        \n",
    "        # Find previous matches based on the criteria\n",
    "        past_matches = df_param[df_param['date'] < date]\n",
    "        \n",
    "        if past_matches.empty:\n",
    "            data_points[f\"{outcome}_{team}_{match_type}_{recency}\"] = 0\n",
    "            continue\n",
    "        \n",
    "        if match_type == matching_encounter:\n",
    "            past_matches = past_matches[\n",
    "                (past_matches['home'] == record['home']) & (past_matches['away'] == record['away'])\n",
    "            ]\n",
    "        elif match_type == inverted_encounter:\n",
    "            past_matches = past_matches[\n",
    "                (past_matches['home'] == record['away']) & (past_matches['away'] == record['home'])\n",
    "            ]\n",
    "        elif match_type == any_rival_home:\n",
    "            past_matches = past_matches[past_matches['home'] == team_name]\n",
    "        elif match_type == any_rival_away:\n",
    "            past_matches = past_matches[past_matches['away'] == team_name]\n",
    "        \n",
    "        if past_matches.empty or len(past_matches) < recency:\n",
    "            data_points[f\"{outcome}_{team}_{match_type}_{recency}\"] = 0\n",
    "            continue\n",
    "        \n",
    "        # Get the specific match at the recency position\n",
    "        specific_match = past_matches.iloc[-recency]\n",
    "        \n",
    "        value = 0\n",
    "        if outcome == goals_for:\n",
    "            if team == home:\n",
    "                value = specific_match['full_time_home_goals']\n",
    "            else:\n",
    "                value = specific_match['full_time_away_goals']\n",
    "        elif outcome == goals_against:\n",
    "            if team == home:\n",
    "                value = specific_match['full_time_away_goals']\n",
    "            else:\n",
    "                value = specific_match['full_time_home_goals']\n",
    "        elif outcome == points_earned:\n",
    "            if team == home:\n",
    "                value = specific_match['full_time_home_points']\n",
    "            else:\n",
    "                value = specific_match['full_time_away_points']\n",
    "        elif outcome == days_since:\n",
    "            last_match_date = specific_match['date']\n",
    "            value = (date - last_match_date).days\n",
    "        \n",
    "        data_points[f\"{outcome}_{team}_{match_type}_{recency}\"] = value\n",
    "    \n",
    "    return data_points\n"
   ],
   "id": "cbda60a1e6271b5a",
   "outputs": [],
   "execution_count": 280
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:51.399264Z",
     "start_time": "2024-07-04T19:52:50.684745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"data/final_dataset.csv\")\n",
    "df.head()\n",
    "\n",
    "# Apply the function to each row and create new columns\n",
    "df[['full_time_home_points', 'full_time_away_points']] = df.apply(calculate_points, axis=1)\n",
    "df['date'] = pd.to_datetime(df['date'], dayfirst=True)\n",
    "\n",
    "# Pre-group the dataframe by home and away teams\n",
    "grouped_home = df.groupby('home')\n",
    "grouped_away = df.groupby('away')\n",
    "\n",
    "# Sample\n",
    "# Test set\n",
    "sample = df.head(1000)\n"
   ],
   "id": "5b7b3b845e1c7bf2",
   "outputs": [],
   "execution_count": 281
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:52:51.403737Z",
     "start_time": "2024-07-04T19:52:51.400265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to apply in parallel\n",
    "def apply_func(record, df_param, criteria_combinations_param):\n",
    "    return extract_data_points(record, df_param, criteria_combinations_param)\n",
    "\n",
    "# Apply the function in parallel\n",
    "def parallelize_dataframe(df_param, func, combinations, n_cores=4):\n",
    "    df_split = np.array_split(df_param, n_cores)\n",
    "    pool = Parallel(n_jobs=n_cores)\n",
    "    func_partial = partial(func, df_param=df_param, combinations=combinations)\n",
    "    results = pool(delayed(lambda d: d.apply(func_partial, axis=1))(d) for d in df_split)\n",
    "    return pd.concat(results, axis=0)\n",
    "\n"
   ],
   "id": "fbc80d71d739a1b",
   "outputs": [],
   "execution_count": 282
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:53:00.908464Z",
     "start_time": "2024-07-04T19:52:51.404739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the function to each record using parallel processing\n",
    "all_data_points = parallelize_dataframe(sample, extract_data_points, all_criteria_combinations, 16)\n",
    "\n",
    "# Convert the extracted data points into columns\n",
    "data_points_df = pd.DataFrame(list(all_data_points))\n",
    "final_df = pd.concat([sample, data_points_df], axis=1)"
   ],
   "id": "6fdca458e7ba3d93",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\JupyterNotebookLBD\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning:\n",
      "\n",
      "'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 283
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:35.112191Z",
     "start_time": "2024-07-04T19:53:00.909465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the function to each record using parallel processing\n",
    "all_data_points_full = parallelize_dataframe(df, extract_data_points, all_criteria_combinations, 16)"
   ],
   "id": "b7d241b77684db8e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coding\\JupyterNotebookLBD\\.venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning:\n",
      "\n",
      "'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 284
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:37.776429Z",
     "start_time": "2024-07-04T19:54:35.112191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Convert the extracted data points into columns\n",
    "data_points_df_full = pd.DataFrame(list(all_data_points_full))\n",
    "final_df_full = pd.concat([df, data_points_df_full], axis=1)"
   ],
   "id": "29d41da6fc658179",
   "outputs": [],
   "execution_count": 285
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:37.935752Z",
     "start_time": "2024-07-04T19:54:37.776429Z"
    }
   },
   "cell_type": "code",
   "source": "final_df_full.to_csv('final_dataset.csv', index=False)",
   "id": "41ebc0f7964bb8fa",
   "outputs": [],
   "execution_count": 286
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:37.941892Z",
     "start_time": "2024-07-04T19:54:37.935752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns_to_drop = [home, away, 'date', 'full_time_home_goals', 'full_time_away_goals', 'full_time_away_points', 'Unnamed: 0']\n",
    "objective_value_plus_prediction_data = final_df_full.drop(columns=columns_to_drop)"
   ],
   "id": "b1ff5966257336ac",
   "outputs": [],
   "execution_count": 287
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:38.519561Z",
     "start_time": "2024-07-04T19:54:37.942892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_column = 'full_time_home_points'\n",
    "scale_factor_labels = 1\n",
    "correlations = objective_value_plus_prediction_data.corr()[target_column].drop(target_column).drop('Unnamed: 0')"
   ],
   "id": "e00ca16bf32c2716",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[288], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m target_column \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_time_home_points\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      2\u001B[0m scale_factor_labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m----> 3\u001B[0m correlations \u001B[38;5;241m=\u001B[39m \u001B[43mobjective_value_plus_prediction_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcorr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtarget_column\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_column\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mUnnamed: 0\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\JupyterNotebookLBD\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:5336\u001B[0m, in \u001B[0;36mSeries.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   5239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[0;32m   5240\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5241\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5248\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   5249\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Series \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5250\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   5251\u001B[0m \u001B[38;5;124;03m    Return Series with specified index labels removed.\u001B[39;00m\n\u001B[0;32m   5252\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   5334\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   5335\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 5336\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   5337\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5338\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5339\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5340\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5341\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5342\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5343\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   5344\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\JupyterNotebookLBD\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4782\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[0;32m   4780\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m   4781\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 4782\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4784\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[0;32m   4785\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[1;32mD:\\Coding\\JupyterNotebookLBD\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4824\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[1;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[0;32m   4822\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m   4823\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 4824\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4825\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[0;32m   4827\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[0;32m   4828\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\Coding\\JupyterNotebookLBD\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7069\u001B[0m, in \u001B[0;36mIndex.drop\u001B[1;34m(self, labels, errors)\u001B[0m\n\u001B[0;32m   7067\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[0;32m   7068\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 7069\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   7070\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[0;32m   7071\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "execution_count": 288
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:38.520563Z",
     "start_time": "2024-07-04T19:54:38.520563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 0.8 Split, as in the MLR work flow.\n",
    "def train_test_split(df_input):\n",
    "    train_data_output = df_input.sample(frac=0.8, random_state=0)\n",
    "    test_data_output = df_input.drop(train_data_output.index)\n",
    "    return train_data_output, test_data_output\n",
    "\n",
    "def get_features_and_labels(train_data_i, test_data_i):\n",
    "    train_features_o = train_data_i.copy()\n",
    "    test_features_o = test_data_i.copy()\n",
    "    \n",
    "    train_labels_o = train_features_o.pop(target_column)\n",
    "    test_labels_o = test_features_o.pop(target_column)\n",
    "    \n",
    "    train_labels_o = train_labels_o / scale_factor_labels\n",
    "    test_labels_o = test_labels_o / scale_factor_labels\n",
    "    \n",
    "    return train_features_o.astype(float), test_features_o.astype(float), train_labels_o.astype(float), test_labels_o.astype(float)"
   ],
   "id": "1a3012e3eda1fe8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T19:54:38.521563Z",
     "start_time": "2024-07-04T19:54:38.521563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data, test_data = train_test_split(final_df_full)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "train_data_nums = train_data.drop(columns=columns_to_drop)\n",
    "test_data_nums = test_data.drop(columns=columns_to_drop)\n",
    "train_features, test_features, train_labels, test_labels = get_features_and_labels(train_data_nums, test_data_nums)\n",
    "\n",
    "train_data_nums.head()"
   ],
   "id": "3fc138c54f97730",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def build_and_compile_model(norm):\n",
    "    model = keras.Sequential([\n",
    "        norm,\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss='mean_absolute_error', optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "    \n",
    "    return model\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.array(train_features))\n",
    "\n",
    "first = np.array(train_features[:1])\n",
    "\n",
    "with np.printoptions(precision=2, suppress=True):\n",
    "    print('First example:', first)\n",
    "    print()\n",
    "    print('Normalized:', normalizer(first).numpy())\n",
    "    \n",
    "sample_data = np.random.rand(100,5)\n",
    "\n",
    "dnn_model = build_and_compile_model(normalizer)\n",
    "dnn_model.summary()"
   ],
   "id": "76fb624cc6d39421",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%%time\n",
    "history_dnn = dnn_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    verbose=0,\n",
    "    validation_split=0.2\n",
    ")"
   ],
   "id": "26c80d6fe6b44817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_loss(history, title):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=history['epoch'], y=history['loss'], mode='lines', name='loss vs epoch'))\n",
    "    fig.add_trace(go.Scatter(x=history['epoch'], y=history['val_loss'], mode='lines', name='val_loss vs epoch'))\n",
    "    fig.update_layout(title=title)\n",
    "    fig.show()"
   ],
   "id": "f3f5e884208c90a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hist_dnn = pd.DataFrame(history_dnn.history)\n",
    "hist_dnn['epoch'] = history_dnn.epoch\n",
    "plot_loss(hist_dnn, \"DNN Training\")"
   ],
   "id": "5673987ac675033",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_results = {}\n",
    "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0) * scale_factor_labels\n",
    "pd.DataFrame(test_results, index=['Mean absolute error '+ target_column]).T"
   ],
   "id": "25d39e718e8ed5fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = dnn_model.predict(test_features)\n",
    "pred_df = pd.DataFrame(predictions).reset_index()"
   ],
   "id": "2bf71f9273601a30",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "comparison = pd.concat([test_data, pred_df], axis=1)\n",
    "\n",
    "pred_df.head(20)\n",
    "test_data.head(20)"
   ],
   "id": "997a93d6c014d791",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "comparison.head(20)",
   "id": "f8257e175367b4b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "comparison.rename(columns={0: 'prediction'}, inplace=True)",
   "id": "60137166adc7924b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:44.887422Z",
     "start_time": "2024-07-04T20:23:44.884888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a function to apply your quantization/labeling logic\n",
    "def label_predictions(value):\n",
    "    if value < 0: # 0.8 is best?\n",
    "        return 0\n",
    "    # elif value < -5: # 0.9 is best?\n",
    "    #     return 1\n",
    "    else:\n",
    "        return 3"
   ],
   "id": "7c33c31716b9bf9b",
   "outputs": [],
   "execution_count": 702
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:44.898364Z",
     "start_time": "2024-07-04T20:23:44.893424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply the function to create a new column 'quantized_label'\n",
    "comparison = comparison.assign(quantized_label=comparison['prediction'].apply(label_predictions))"
   ],
   "id": "3639e2321c2b499e",
   "outputs": [],
   "execution_count": 703
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:44.930878Z",
     "start_time": "2024-07-04T20:23:44.927433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comparison['successful_prediction'] = comparison['quantized_label'] == comparison['full_time_home_points']\n",
    "comparison['prediction_failure_type'] = comparison['quantized_label'] - comparison['full_time_home_points']"
   ],
   "id": "5084a2980c046aac",
   "outputs": [],
   "execution_count": 704
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:44.955723Z",
     "start_time": "2024-07-04T20:23:44.952804Z"
    }
   },
   "cell_type": "code",
   "source": "outcome_and_prediction = comparison[['quantized_label', 'full_time_home_points', 'successful_prediction', 'prediction_failure_type', 'prediction']]\n",
   "id": "522855b090b9ee7c",
   "outputs": [],
   "execution_count": 705
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:44.991793Z",
     "start_time": "2024-07-04T20:23:44.984806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "outcome_and_prediction['full_time_home_points'].value_counts()\n",
    "ordered_by_real = comparison.sort_values(by='full_time_home_points', ascending=True)\n",
    "ordered_by_prediction = comparison.sort_values(by='prediction', ascending=True)\n",
    "\n",
    "\n",
    "outcome_and_prediction['prediction_failure_type'].value_counts()"
   ],
   "id": "5d483e7428027ab0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction_failure_type\n",
       " 0    669\n",
       " 3    325\n",
       " 2    306\n",
       "-3     41\n",
       "-1     27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 706
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:45.032024Z",
     "start_time": "2024-07-04T20:23:45.028683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "first_draw_index = ordered_by_real[ordered_by_real['full_time_home_points'] == 1].index[0]\n",
    "# prediction_draw_cutoff = ordered_by_prediction.index[first_draw_index]['prediction']\n",
    "print(first_draw_index)"
   ],
   "id": "b16a1599f0ced017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    }
   ],
   "execution_count": 707
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:23:45.050619Z",
     "start_time": "2024-07-04T20:23:45.046028Z"
    }
   },
   "cell_type": "code",
   "source": "comparison['full_time_home_points'].value_counts()",
   "id": "b55f72f4a911969f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_time_home_points\n",
       "3    657\n",
       "0    378\n",
       "1    333\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 708
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:24:28.863293Z",
     "start_time": "2024-07-04T20:24:28.859922Z"
    }
   },
   "cell_type": "code",
   "source": "print(669/1369)",
   "id": "95c114ec58cbb6f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48867786705624544\n"
     ]
    }
   ],
   "execution_count": 710
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:25:07.707300Z",
     "start_time": "2024-07-04T20:25:07.702131Z"
    }
   },
   "cell_type": "code",
   "source": "final_df_full['full_time_home_points'].value_counts()",
   "id": "c1eed4925944a314",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "full_time_home_points\n",
       "3    3176\n",
       "0    1913\n",
       "1    1751\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 711
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:25:33.431363Z",
     "start_time": "2024-07-04T20:25:33.427915Z"
    }
   },
   "cell_type": "code",
   "source": "print(3176/(3176+1913+1751))",
   "id": "13980dd618e22f4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.464327485380117\n"
     ]
    }
   ],
   "execution_count": 712
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-04T20:35:15.461995Z",
     "start_time": "2024-07-04T20:35:15.445164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_value = 3\n",
    "target_value_column = 'full_time_home_points'\n",
    "# Step 2: Count occurrences of value 1 in 'value_column' and compute proportion\n",
    "def compute_proportion(group):\n",
    "    counts = group[target_value_column].value_counts()\n",
    "    if target_value in counts:\n",
    "        proportion = counts[target_value] / len(group)\n",
    "    else:\n",
    "        proportion = 0\n",
    "    return proportion\n",
    "\n",
    "result = grouped_home.apply(compute_proportion).reset_index()\n",
    "result.columns = ['team', 'home wins proportion']\n",
    "sorted = result.sort_values(by='home wins proportion', ascending=False)\n",
    "\n",
    "print(sorted)"
   ],
   "id": "67efb29f546ec7b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                team  home wins proportion\n",
      "25        Man United              0.730994\n",
      "0            Arsenal              0.690058\n",
      "12           Chelsea              0.681287\n",
      "23         Liverpool              0.605263\n",
      "24          Man City              0.591331\n",
      "38         Tottenham              0.578947\n",
      "26       Middlesboro              0.526316\n",
      "16           Everton              0.508772\n",
      "28         Newcastle              0.467105\n",
      "17            Fulham              0.453441\n",
      "20           Ipswich              0.447368\n",
      "35             Stoke              0.426316\n",
      "21             Leeds              0.421053\n",
      "34       Southampton              0.411483\n",
      "3          Blackburn              0.411483\n",
      "41          West Ham              0.407018\n",
      "30        Portsmouth              0.406015\n",
      "11          Charlton              0.406015\n",
      "32           Reading              0.403509\n",
      "22         Leicester              0.390977\n",
      "5             Bolton              0.387560\n",
      "37           Swansea              0.383459\n",
      "2         Birmingham              0.375940\n",
      "9            Burnley              0.368421\n",
      "1        Aston Villa              0.368421\n",
      "8           Brighton              0.368421\n",
      "33  Sheffield United              0.368421\n",
      "6        Bournemouth              0.368421\n",
      "29           Norwich              0.357895\n",
      "27     Middlesbrough              0.356725\n",
      "14    Crystal Palace              0.342105\n",
      "40         West Brom              0.320175\n",
      "42             Wigan              0.315789\n",
      "39           Watford              0.315789\n",
      "18      Huddersfield              0.315789\n",
      "19              Hull              0.305263\n",
      "36        Sunderland              0.304511\n",
      "43            Wolves              0.302632\n",
      "4          Blackpool              0.263158\n",
      "31               QPR              0.263158\n",
      "10           Cardiff              0.263158\n",
      "15             Derby              0.245614\n",
      "13          Coventry              0.210526\n",
      "7           Bradford              0.210526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thele\\AppData\\Local\\Temp\\ipykernel_13176\\2288138269.py:12: DeprecationWarning:\n",
      "\n",
      "DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 715
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "897ab9379267d560"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
